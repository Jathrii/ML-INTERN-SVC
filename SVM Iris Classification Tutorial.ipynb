{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM Iris Classification Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial was made to complete Week 2's task for the ML Internship. It involves making a classification model to classify 3 different types of iris plants by using the data in the [Iris Dataset](https://www.google.com \"UCI Machine Learning Repository\") to develop an SVM large margin classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing The Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start by importing the libaries we'll need to load our data and develop & test our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import datasets\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll load that Iris dataset from scikit-learn's datasets and we'll use [StandardScaler](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html \"sklearn.preprocessing.StandardScaler\") to normalize our data then we'll use [train_test_split](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html \"sklearn.model_selection.train_test_split\") to shuffle the data to remove any ordering bias, then we'll split it into two subsets, 80% training & 20% testing.\n",
    "\n",
    "It's important to set `random_state` equal to some constant so we can reproduce our results everytime time we run the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the Iris dataset\n",
    "iris = datasets.load_iris()\n",
    "features = iris.data\n",
    "classes = iris.target\n",
    "\n",
    "# Normalizing the data\n",
    "scaler = StandardScaler()\n",
    "normalized = scaler.fit_transform(features, classes)\n",
    "\n",
    "# Shuffling the data then splitting it into 80% training data & 20% testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(normalized, classes, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting the right algorithm/model for a machine learning application is often not as straight forward as one would hope, it usually requires considerable knowledge of the field and of the dataset used in the application and what we wish to get out of it.\n",
    "\n",
    "Fortunately for us, this choice has already been narrowed quite a bit for us as this is an SVM tutorial after all. And we can narrow it further using this [cheat-sheet](http://scikit-learn.org/stable/tutorial/machine_learning_map/index.html) provided by scikit-learn:\n",
    "![scikit-learn algorithm cheat-sheet](http://scikit-learn.org/stable/_static/ml_map.png)\n",
    "\n",
    "By following the steps provided above, we'll find that a Linear SVC model fits our dataset which consists of 150 labeled samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even when the model choice is made easy for us and we're provided with efficient implementations of the algorithms, there's still one very important factor we have to take into consideration, and that factor is our choice of **hyperparameters**.\n",
    "\n",
    "In our case, we simply need to find a good choice for the regularization parameter **C** which essentially tells our SVM model how much we care about correctly seperating as many instaces as possible versus having the largest minimum margin.\n",
    "\n",
    "Since the theory for determining how to set C is not very well developed at the moment, most people tend to use cross-validation, which is exactly what we're about to do.\n",
    "\n",
    "One very effective (and equally very expensive) method for hyperparameter optimization is using grid search alongside cross-validation to find the optimal hyperparameter values for our model by training our model using all the provided hyperparameter combinations and comparing their performance until we find the best one. While such brute force algorithms might be too computaionally heavy for larger datasets, it's not really an issue for our case as we only have 4 features and 150 samples, which our machines can easily work through in no time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementaion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have chosen our model and algorithms, we'll proceed to use the implentations provided by scikit-learn to train our model and evaluate its accuracy.\n",
    "\n",
    "As we decided earlier, our classifier is [LinearSVC](http://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html \"sklearn.svm.LinearSVC\"), we set `random_state` equal to some constant for reproducibility like we did with train_test_split earlier.\n",
    "\n",
    "Our hyperparameter optimization algorithm is [GridSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html \"sklearn.model_selection.GridSearchCV\"), we'll feed it the classifier, the possible values for the hyperparameter we want to optimize (**C**) and the number of cross-validation folds to use.\n",
    "\n",
    "Note that for the params variable we chose a logspace with `base=2` with a `start=10^-5` and `stop=10^20` with `num=50` being the default value for the number of points in the logspace. These values are experimental values that happened to provide the best results for this specific model and data. Feel free to experiment with your own values to see how the results change and whether or not you can get better results than the ones shown in this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up our LinearSVC classifier\n",
    "classifier = LinearSVC(loss='hinge', multi_class='ovr', random_state=0)\n",
    "\n",
    "# Logspace with experimental parameters to provide the best results for our specifi model and data\n",
    "params = {'C': np.logspace(10^-5, 10^20, base=2)}\n",
    "\n",
    "# Feeding our classifier, params and number of cross-validation \n",
    "grid = GridSearchCV(classifier, params, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we run GridSearchCV to fit the model using our training data and then we take the best classifier it produces from the `best_estimator_` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal C value for our model: 470.337000\n"
     ]
    }
   ],
   "source": [
    "# Fitting the model\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Taking the best classifier\n",
    "best_clf = grid.best_estimator_\n",
    "print('The optimal C value for our model: %f' %best_clf.C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now that we have our best classifier, let's measure its accuracy on our training data using LinearSVC's `score` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.966667\n"
     ]
    }
   ],
   "source": [
    "# Printing the model's accuracy on the training data\n",
    "print('Training Accuracy: %f' %best_clf.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got an accuracy of 96.67%, which is pretty high but it's still not 100%. This makes sense since the labels in the Iris dataset are only partially linearlly seperable, so we can't really classify them with 100% accuracy using our linear SVC model.\n",
    "\n",
    "Now let's see if this outcome is generalizable by measuring the classifier's accuracy on our testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 1.000000\n"
     ]
    }
   ],
   "source": [
    "# Printing the model's accuracy on the testing data\n",
    "print('Testing Accuracy: %f' %best_clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surprisingly enough, our model managed to classifiy our testing data with 100% accuracy. This can be attributed to many factors like the size of our dataset being small and easier to model and also luck, as this means the subset of the data we reserved for training was linearly seperable and therefore it can be accurately and completly classified using our Linear SVC model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
